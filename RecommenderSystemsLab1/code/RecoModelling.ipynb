{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems based on neighborhood based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import operator\n",
    "from statistics import mean,pstdev\n",
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../ml-latest-small/\"\n",
    "ratings_path=path+\"ratings.csv\"\n",
    "movies_path=path+\"movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df=pd.read_csv(ratings_path)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix is sparse, so all the movies may not be there, so we need an index to movieId mapping so that we can save space in matrix generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_indices=[] \n",
    "inverse_movie_map={}\n",
    "movies_df=pd.read_csv(movies_path)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two steps given below can optimised by converting lists into sets and taking their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movies_df)):\n",
    "    movie_indices.append(movies_df['movieId'][i])\n",
    "    inverse_movie_map[movies_df['movieId'][i]]=i\n",
    "number_of_items=len(movie_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_users={}\n",
    "for i in range(len(ratings_df)):\n",
    "    number_of_users[ratings_df['userId'][i]]=1\n",
    "number_of_users=len(number_of_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nos=random.sample(range(100836), int(0.7*100836))\n",
    "test_nos=list(range(0,len(ratings_df)))\n",
    "test_nos=list(set(test_nos)-set(train_nos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our ratings matrix, note that we only put the values from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix_train=np.zeros(shape=(number_of_users,number_of_items))\n",
    "ratings_matrix_train.fill(np.nan)\n",
    "for i in train_nos:\n",
    "\n",
    "    user_id=ratings_df['userId'][i]-1\n",
    "    movie_id=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    ratings_matrix_train[user_id][movie_id]=ratings_df['rating'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_with_nan(list_a):\n",
    "    count=0\n",
    "    sum=0.0\n",
    "    for i in list_a:\n",
    "        if not np.isnan(i):\n",
    "            #print(i)\n",
    "            count+=1\n",
    "            sum+=i\n",
    "    #print(sum) \n",
    "    if(count==0):\n",
    "        return 0\n",
    "    return sum/count        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_coff(a,b):\n",
    "    mean_a=mean_with_nan(a)\n",
    "    mean_b=mean_with_nan(b)\n",
    "    #print(mean_a)\n",
    "    #print(mean_b)\n",
    "    num=0.0\n",
    "    den_left=0.0\n",
    "    den_right=0.0\n",
    "    for i in range(len(a)):\n",
    "        if (not np.isnan(a[i])) and (not np.isnan(b[i])):\n",
    "            num+=(a[i]-mean_a)*(b[i]-mean_b)\n",
    "            den_left+=(a[i]-mean_a)*(a[i]-mean_a)\n",
    "            den_right+=(b[i]-mean_b)*(b[i]-mean_b)\n",
    "    den_left=np.sqrt(den_left)\n",
    "    #print(den_left)\n",
    "    den_right=np.sqrt(den_right)\n",
    "    #print(den_right)\n",
    "    if (den_right==0 or den_left==0):\n",
    "        return -1\n",
    "    return num/((den_left)*(den_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating User Similarity Matrix based on pearson coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sim_matrix_pearson=np.zeros(shape=(number_of_users,number_of_users))\n",
    "user_sim_matrix_pearson.fill(np.nan)\n",
    "for i in range(0,number_of_users):\n",
    "    for j in range(i,number_of_users):\n",
    "        user_sim_matrix_pearson[i][j]=pearson_coff(ratings_matrix_train[i],ratings_matrix_train[j])\n",
    "        user_sim_matrix_pearson[j][i]=user_sim_matrix_pearson[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a,b):\n",
    "    mean_a=mean_with_nan(a)\n",
    "    mean_b=mean_with_nan(b)\n",
    "    #print(mean_a)\n",
    "    #print(mean_b)\n",
    "    num=0.0\n",
    "    den_left=0.0\n",
    "    den_right=0.0\n",
    "    for i in range(len(a)):\n",
    "        if (not np.isnan(a[i])) and (not np.isnan(b[i])):\n",
    "            num+=(a[i])*(b[i])\n",
    "            den_left+=(a[i])*(a[i])\n",
    "            den_right+=(b[i])*(b[i])\n",
    "    den_left=np.sqrt(den_left)\n",
    "    #print(den_left)\n",
    "    den_right=np.sqrt(den_right)\n",
    "    #print(den_right)\n",
    "    if (den_right==0 or den_left==0):\n",
    "        return -1\n",
    "    return num/((den_left)*(den_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating User Similarity Matrix based on cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sim_matrix_cosine=np.zeros(shape=(number_of_users,number_of_users))\n",
    "user_sim_matrix_cosine.fill(np.nan)\n",
    "for i in range(0,number_of_users):\n",
    "    for j in range(i,number_of_users):\n",
    "        user_sim_matrix_cosine[i][j]=cosine_sim(ratings_matrix_train[i],ratings_matrix_train[j])\n",
    "        user_sim_matrix_cosine[j][i]=user_sim_matrix_cosine[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(path+'user_sim_matrix_cosine',user_sim_matrix_cosine)\n",
    "# np.save(path+'user_sim_matrix_pearson',user_sim_matrix_pearson)\n",
    "# np.save(path+'ratings_matrix_train',ratings_matrix_train)\n",
    "# np.save(path+'train_nos',train_nos)\n",
    "# np.save(path+'test_nos',test_nos)\n",
    "#np.save(path+'ratings_matrix_train_mean_centred',ratings_matrix_train_mean_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions=[]\n",
    "for i in test_nos:\n",
    "    correct_predictions.append(ratings_df['rating'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdv_with_nan(list_a):\n",
    "\n",
    "    list_b=[]\n",
    "    for i in list_a:\n",
    "        if not np.isnan(i):\n",
    "            #print(i)\n",
    "            list_b.append(k)\n",
    "    #print(sum) \n",
    "    if(len(list_b)<2):\n",
    "        return 0.00001\n",
    "    if (pstdev(list_b)!=0):\n",
    "        return pstdev(list_b)\n",
    "    return 0.00001\n",
    "    #return sum/count      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(a,b):\n",
    "    error_sum=0.0\n",
    "    for i in range(len(a)):\n",
    "        error_sum+=abs(a[i]-b[i])\n",
    "    error_sum/=len(a)\n",
    "    return error_sum        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_error(a,b):\n",
    "    error_sum=0.0\n",
    "    for i in range(len(a)):\n",
    "        error_sum+=(a[i]-b[i])*(a[i]-b[i])\n",
    "    error_sum/=len(a)\n",
    "    return np.sqrt(error_sum)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding predictions without using mean centring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "pearson_raw_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    for j in range(0,number_of_users):\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                top_k_similar_users_same_item_rated.append((user_sim_matrix_pearson[user_no][j],ratings_matrix_train[j][movie_no]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        pearson_raw_result.append(num/den) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        pearson_raw_result.append(num/den) \n",
    "    else:\n",
    "        pearson_raw_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "cosine_raw_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    for j in range(0,number_of_users):\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                top_k_similar_users_same_item_rated.append((user_sim_matrix_cosine[user_no][j],ratings_matrix_train[j][movie_no]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        cosine_raw_result.append(num/den) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        cosine_raw_result.append(num/den) \n",
    "    else:\n",
    "        cosine_raw_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding predictions with using mean centring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "cosine_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    for j in range(0,number_of_users):\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                top_k_similar_users_same_item_rated.append((user_sim_matrix_cosine[user_no][j],ratings_matrix_train[j][movie_no]-mean_of_users[j]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        cosine_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "            \n",
    "        cosine_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    else:\n",
    "        cosine_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "pearson_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    for j in range(0,number_of_users):\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                top_k_similar_users_same_item_rated.append((user_sim_matrix_pearson[user_no][j],ratings_matrix_train[j][movie_no]-mean_of_users[j]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        pearson_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "            \n",
    "        pearson_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    else:\n",
    "        pearson_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_error(correct_predictions,pearson_result))\n",
    "print(rmse_error(correct_predictions,cosine_result))\n",
    "print(rmse_error(correct_predictions,pearson_raw_result))\n",
    "print(rmse_error(correct_predictions,cosine_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(correct_predictions,pearson_result))\n",
    "print(mean_absolute_error(correct_predictions,cosine_result))\n",
    "print(mean_absolute_error(correct_predictions,pearson_raw_result))\n",
    "print(mean_absolute_error(correct_predictions,cosine_raw_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using z score for predictions, i.e, accounting for standard deviation as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "pearson_std_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    for j in range(0,number_of_users):\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                top_k_similar_users_same_item_rated.append((user_sim_matrix_pearson[user_no][j],(ratings_matrix_train[j][movie_no]-mean_of_users[j])/stdv_with_nan(ratings_matrix_train[j])))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        pearson_std_result.append(mean_of_users[user_no]+stdv_with_nan(ratings_matrix_train[user_no])*(num/den)) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "            \n",
    "        pearson_std_result.append(mean_of_users[user_no]+stdv_with_nan(ratings_matrix_train[user_no])*(num/den)) \n",
    "    else:\n",
    "        pearson_std_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_error(correct_predictions,pearson_std_result))\n",
    "print(mean_absolute_error(correct_predictions,pearson_std_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Long_Tail issue, using inverse user frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=[]\n",
    "for i in range(number_of_items):\n",
    "    count=0.000005\n",
    "    for j in range(number_of_users):\n",
    "        if(not np.isnan(ratings_matrix_train[j][i])):\n",
    "            count+=1\n",
    "    weights.append(np.log(number_of_users/count))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict={}\n",
    "for i in range(number_of_users):\n",
    "    user_dict[i]=[]\n",
    "    for j in range(number_of_items):\n",
    "        if(not np.isnan(ratings_matrix_train[i][j])):\n",
    "            user_dict[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(a,b):\n",
    "    mean_a=mean_of_users[a]\n",
    "    mean_b=mean_of_users[b]\n",
    "    #print(mean_a)\n",
    "    #print(mean_b)\n",
    "    num=0.0\n",
    "    den_left=0.0\n",
    "    den_right=0.0\n",
    "    for i in user_dict[a]:\n",
    "\n",
    "        if (not np.isnan(ratings_matrix_train[b][i])):\n",
    "            rating_a=ratings_matrix_train[a][i]\n",
    "            rating_b=ratings_matrix_train[b][i]\n",
    "            num+=(rating_a-mean_a)*(rating_b-mean_b)*weights[i]\n",
    "            den_left+=(rating_a-mean_a)*(rating_a-mean_a)*weights[i]\n",
    "            den_right+=(rating_b-mean_b)*(rating_b-mean_b)*weights[i]\n",
    "    den_left=np.sqrt(den_left)\n",
    "    #print(den_left)\n",
    "    den_right=np.sqrt(den_right)\n",
    "    #print(den_right)\n",
    "    if (den_right==0 or den_left==0):\n",
    "        return -1\n",
    "    return num/((den_left)*(den_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_tail=np.zeros(shape=(number_of_users,number_of_users))\n",
    "sim_matrix_tail.fill(np.nan)\n",
    "for i in range(0,number_of_users):\n",
    "    if(i%50==0):\n",
    "        print(i)\n",
    "    for j in range(i,number_of_users):\n",
    "        sim_matrix_tail[i][j]=sim(i,j)\n",
    "        sim_matrix_tail[j][i]=sim_matrix_tail[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "tail_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    for j in range(0,number_of_users):\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                top_k_similar_users_same_item_rated.append((sim_matrix_tail[user_no][j],ratings_matrix_train[j][movie_no]-mean_of_users[j]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        tail_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "            \n",
    "        tail_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    else:\n",
    "        tail_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creating item similarity matrices based on pearson coefficient and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_matrix_pearson=np.zeros(shape=(number_of_items,number_of_items))\n",
    "item_sim_matrix_pearson.fill(np.nan)\n",
    "for i in range(0,number_of_items):\n",
    "    if(i%50==0):\n",
    "        print(i)\n",
    "    for j in range(i,number_of_items):\n",
    "        item_sim_matrix_pearson[i][j]=pearson_coff(ratings_matrix_train[:,i],ratings_matrix_train[:,j])\n",
    "        item_sim_matrix_pearson[j][i]=item_sim_matrix_pearson[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_matrix_cosine=np.zeros(shape=(number_of_items,number_of_items))\n",
    "item_sim_matrix_cosine.fill(np.nan)\n",
    "for i in range(0,number_of_items):\n",
    "    if(i%50==0):\n",
    "        print(i)\n",
    "    for j in range(i,number_of_items):\n",
    "        item_sim_matrix_cosine[i][j]=cosine_sim(ratings_matrix_train[:,i],ratings_matrix_train[:,j])\n",
    "        item_sim_matrix_cosine[j][i]=item_sim_matrix_cosine[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "cosine_item_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_items_same_users_rated=[]\n",
    "    for j in range(0,number_of_items):\n",
    "        if(j!=movie_no):\n",
    "            if(not np.isnan(ratings_matrix_train[user_no][j])):\n",
    "                top_k_similar_items_same_users_rated.append((item_sim_matrix_cosine[movie_no][j],ratings_matrix_train[user_no][j]-mean_of_items[j]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_items_same_users_rated=sorted(top_k_similar_items_same_users_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_items_same_users_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_items_same_users_rated[p][0]*top_k_similar_items_same_users_rated[p][1]\n",
    "            den+=abs(top_k_similar_items_same_users_rated[p][0])\n",
    "        cosine_item_result.append(mean_of_items[movie_no]+(num/den)) \n",
    "    elif(len(top_k_similar_items_same_users_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_items_same_users_rated)):\n",
    "            num+=top_k_similar_items_same_users_rated[p][0]*top_k_similar_items_same_users_rated[p][1]\n",
    "            den+=abs(top_k_similar_items_same_users_rated[p][0])\n",
    "            \n",
    "        cosine_item_result.append(mean_of_items[item_no]+(num/den)) \n",
    "    else:\n",
    "        cosine_item_result.append(mean_with_nan(ratings_matrix_train[:,movie_no]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "pearson_item_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_items_same_users_rated=[]\n",
    "    for j in range(0,number_of_items):\n",
    "        if(j!=movie_no):\n",
    "            if(not np.isnan(ratings_matrix_train[user_no][j])):\n",
    "                top_k_similar_items_same_users_rated.append((item_sim_matrix_pearson[movie_no][j],ratings_matrix_train[user_no][j]-mean_of_items[j]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_items_same_users_rated=sorted(top_k_similar_items_same_users_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.0\n",
    "    if(not len(top_k_similar_items_same_users_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_items_same_users_rated[p][0]*top_k_similar_items_same_users_rated[p][1]\n",
    "            den+=abs(top_k_similar_items_same_users_rated[p][0])\n",
    "        pearson_item_result.append(mean_of_items[movie_no]+(num/den)) \n",
    "    elif(len(top_k_similar_items_same_users_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_items_same_users_rated)):\n",
    "            num+=top_k_similar_items_same_users_rated[p][0]*top_k_similar_items_same_users_rated[p][1]\n",
    "            den+=abs(top_k_similar_items_same_users_rated[p][0])\n",
    "            \n",
    "        pearson_item_result.append(mean_of_items[item_no]+(num/den)) \n",
    "    else:\n",
    "        pearson_item_result.append(mean_with_nan(ratings_matrix_train[:,movie_no]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_error(correct_predictions,pearson_item_result))\n",
    "print(rmse_error(correct_predictions,cosine_item_result))\n",
    "print(mean_absolute_error(correct_predictions,pearson_item_result))\n",
    "print(mean_absolute_error(correct_predictions,cosine_item_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying fusion of both(user and item based approaches)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_list(a,b):\n",
    "    c=[]\n",
    "    for i in range(len(a)):\n",
    "        c.append((a[i]+b[i])/2)\n",
    "    return c    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_list_1(a,b,error_a,error_b):\n",
    "    c=[]\n",
    "    for i in range(len(a)):\n",
    "        c.append((a[i]*error_b+b[i]*error_a)/(error_a+error_b))\n",
    "    return c    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_pearson=mean_list(pearson_result,pearson_item_result)\n",
    "hybrid_cosine=mean_list(cosine_result,cosine_item_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(correct_predictions,mean_list_1(cosine_result,cosine_item_result,cosine_error,cosine_item_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using K Means to determine neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(a,b):\n",
    "    dist=0.0\n",
    "    count=0\n",
    "    for i in range(len(a)):\n",
    "        if(not np.isnan(a[i]) and not np.isnan(b[i])):\n",
    "            dist+=abs(a[i]-b[i])\n",
    "            count+=1\n",
    "    if(count==0):\n",
    "        return 99;\n",
    "    else:\n",
    "        return dist/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix=np.zeros(shape=(number_of_users,number_of_users))\n",
    "dist_matrix.fill(np.nan)\n",
    "for i in range(number_of_users):\n",
    "    if(i%50==0):\n",
    "        print(i)\n",
    "    dist_matrix[i][i]=0\n",
    "    for j in range(i,number_of_users):\n",
    "        dist_matrix[i][j]=manhattan_distance(ratings_matrix_train[i],ratings_matrix_train[j])\n",
    "        dist_matrix[j][i]=dist_matrix[i][j]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sim(list_a):\n",
    "    sim_sum=0.0\n",
    "    count=len(list_a)\n",
    "    for i in range(len(list_a)):\n",
    "        sim_sum+=list_a[i]\n",
    "    if(count==0):\n",
    "        return -1\n",
    "    return sim_sum/count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(number_of_users):\n",
    "    user_sim_matrix_pearson[i][i]=1.000000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20\n",
    "centroids={}\n",
    "for i in range(k):\n",
    "    centroids[i+20]=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main K-Means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(13):\n",
    "    for key in centroids:\n",
    "        centroids[key]=[]    \n",
    "    for i in range(number_of_users):\n",
    "        max_sim=-99999\n",
    "        max_cent=-1\n",
    "        for key in centroids:\n",
    "            if(max_sim<user_sim_matrix_pearson[key][i]):\n",
    "                max_sim=user_sim_matrix_pearson[key][i]\n",
    "                max_cent=key\n",
    "                #print(str(max_sim)+\" \"+str(max_cent)+\" \"+str(i))\n",
    "        centroids[max_cent].append(i)\n",
    "    #print(centroids) \n",
    "    #print('\\n')\n",
    "    centroids1={}    \n",
    "    for key in centroids:\n",
    "        #print(key)\n",
    "        \n",
    "        list_a=centroids[key]\n",
    "        #print(list_a)\n",
    "        max_sim=-9999999\n",
    "        new_centroid=key\n",
    "        for j in range(len(list_a)):\n",
    "            list_cur=[]\n",
    "            for k in range(len(list_a)):\n",
    "                if(j!=k):\n",
    "                    list_cur.append(user_sim_matrix_pearson[j][k])\n",
    "                    \n",
    "            cur_sim=mean_sim(list_cur)\n",
    "            if(max_sim<cur_sim):\n",
    "                max_sim=cur_sim\n",
    "                new_centroid=list_a[j]\n",
    "#                 print(cur_sim)\n",
    "#             else:\n",
    "#                 print(cur_sim)\n",
    "        #print(new_centroid)\n",
    "        centroids1[new_centroid]=[]\n",
    "        #print(centroids1)\n",
    "    centroids=centroids1 \n",
    "    #print(centroids)\n",
    "    for key in centroids:\n",
    "        centroids[key]=[]    \n",
    "    for i in range(number_of_users):\n",
    "        max_sim=-1.1\n",
    "        max_cent=-1\n",
    "        for key in centroids:\n",
    "            if(max_sim<user_sim_matrix_pearson[key][i]):\n",
    "                max_sim=user_sim_matrix_pearson[key][i]\n",
    "                max_cent=key\n",
    "        centroids[max_cent].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict={}\n",
    "for key in centroids:\n",
    "    cluster_dict[key]=key\n",
    "    list_a=centroids[key]\n",
    "    for i in list_a:\n",
    "        cluster_dict[i]=key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only entries present in cluster for prediction (basic KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "pearson_kmeans_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    this_key=cluster_dict[user_no]\n",
    "    this_list=centroids[this_key]\n",
    "    for j in this_list:\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                top_k_similar_users_same_item_rated.append((user_sim_matrix_pearson[user_no][j],ratings_matrix_train[j][movie_no]-mean_of_users[j]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.00000009\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        pearson_kmeans_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "            \n",
    "        pearson_kmeans_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    else:\n",
    "        pearson_kmeans_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_error(correct_predictions,pearson_kmeans_result))\n",
    "print(mean_absolute_error(correct_predictions,pearson_kmeans_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extending Normal KMeans for data smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_matrix=np.zeros(shape=(number_of_users,number_of_items))\n",
    "for i in range(number_of_users):\n",
    "    for j in range(number_of_items):\n",
    "        if(np.isnan(ratings_matrix_train[i][j])):\n",
    "            check_matrix[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(number_of_users):\n",
    "    for j in range(number_of_items):\n",
    "        if(np.isnan(ratings_matrix_train[i][j])):\n",
    "            Ru_bar=mean_of_users[i]\n",
    "            this_key=cluster_dict[i]\n",
    "            list_a=centroids[this_key]\n",
    "            num=0.0\n",
    "            den=0\n",
    "            for k in list_a:\n",
    "                if(check_matrix[k][j]==0):\n",
    "                    num+=ratings_matrix_train[k][j]-mean_of_users[k]\n",
    "                    den+=1\n",
    "            to_add=0\n",
    "            if(den>0):\n",
    "                to_add=num/den\n",
    "            ratings_matrix_train[i][j]=Ru_bar+to_add    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix_train=np.load(path+\"fake_ratings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.6\n",
    "def new_sim(a,b,mean_a,mean_b,a_no):\n",
    "#     mean_a=mean_with_nan(a)\n",
    "#     mean_b=mean_with_nan(b)\n",
    "    #print(mean_a)\n",
    "    #print(mean_b)\n",
    "    num=0.0\n",
    "    den_left=0.0\n",
    "    den_right=0.0\n",
    "    for i in range(len(a)):\n",
    "        if (not np.isnan(a[i])) and (not np.isnan(b[i])):\n",
    "            w=0\n",
    "            if(check_matrix[a_no][i]==0):\n",
    "                w=weight\n",
    "            else:\n",
    "                w=1-weight\n",
    "            \n",
    "            num+=(a[i]-mean_a)*(b[i]-mean_b)*w\n",
    "            den_left+=(a[i]-mean_a)*(a[i]-mean_a)*w*w\n",
    "            den_right+=(b[i]-mean_b)*(b[i]-mean_b)\n",
    "    den_left=np.sqrt(den_left)\n",
    "    #print(den_left)\n",
    "    den_right=np.sqrt(den_right)\n",
    "    #print(den_right)\n",
    "    if (den_right==0 or den_left==0):\n",
    "        return -1\n",
    "    return num/((den_left)*(den_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_sim_matrix=np.ones(shape=(number_of_users,number_of_users))\n",
    "for i in range(number_of_users):\n",
    "    if(i%50==0):\n",
    "        print(i)\n",
    "    for j in range(number_of_users):\n",
    "        if(i!=j):\n",
    "            latest_sim_matrix[i][j]=new_sim(ratings_matrix_train[i],ratings_matrix_train[j],mean_of_users[i],mean_of_users[j],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+\"latest_sim_matrix\",latest_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Ratings after data smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "second_kmeans_result=[]\n",
    "for i in test_nos:\n",
    "    movie_no=inverse_movie_map[ratings_df['movieId'][i]]\n",
    "    user_no=ratings_df['userId'][i]-1\n",
    "    \n",
    "    top_k_similar_users_same_item_rated=[]\n",
    "    this_key=cluster_dict[user_no]\n",
    "    this_list=centroids[this_key]\n",
    "    for j in this_list:\n",
    "        if(j!=user_no):\n",
    "            if(not np.isnan(ratings_matrix_train[j][movie_no])):\n",
    "                w=0\n",
    "                if(check_matrix[j][movie_no]==0):\n",
    "                    w=weight\n",
    "                else:\n",
    "                    w=1-weight\n",
    "                top_k_similar_users_same_item_rated.append((w*latest_sim_matrix[user_no][j],ratings_matrix_train[j][movie_no]-mean_of_users[j]))\n",
    "    #print(len(top_k_similar_users_same_item_rated))\n",
    "    #print(top_k_similar_users_same_item_rated)            \n",
    "    top_k_similar_users_same_item_rated=sorted(top_k_similar_users_same_item_rated,key=lambda x: x[0],reverse=True)  \n",
    "    num=0.0\n",
    "    den=0.00000009\n",
    "    if(not len(top_k_similar_users_same_item_rated)<k):\n",
    "        for p in range(0,k):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "        second_kmeans_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    elif(len(top_k_similar_users_same_item_rated)>0):\n",
    "        for p in range(0,len(top_k_similar_users_same_item_rated)):\n",
    "            num+=top_k_similar_users_same_item_rated[p][0]*top_k_similar_users_same_item_rated[p][1]\n",
    "            den+=abs(top_k_similar_users_same_item_rated[p][0])\n",
    "            \n",
    "        second_kmeans_result.append(mean_of_users[user_no]+(num/den)) \n",
    "    else:\n",
    "        second_kmeans_result.append(mean_with_nan(ratings_matrix_train[user_no]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_error(correct_predictions,second_kmeans_result))\n",
    "print(mean_absolute_error(correct_predictions,second_kmeans_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

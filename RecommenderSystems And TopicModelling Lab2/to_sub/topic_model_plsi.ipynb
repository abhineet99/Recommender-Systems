{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "YNidhn8hLArg",
    "outputId": "cba6ff61-8a17-4d05-bae0-380160360f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer \n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "K3GIK1s8LRU0",
    "outputId": "a9f0ef5e-ac29-43c0-ff11-28e02db544b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.16.1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "u03KrWg_LSwa",
    "outputId": "2900ef00-41b8-423e-b9cb-f10de85289ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fkP9e2MwLc5a",
    "outputId": "db66b76f-0fb4-4ac0-feec-64615c2e4bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/RecommenderSystems And TopicModelling Lab2\n"
     ]
    }
   ],
   "source": [
    "cd drive/My Drive/RecommenderSystems And TopicModelling Lab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SArs3zlwLjWZ"
   },
   "outputs": [],
   "source": [
    "path=\"data/\"\n",
    "news_path=path+\"nytimes_news_articles.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wW6y-5IYLkvH"
   },
   "outputs": [],
   "source": [
    "stopwords=np.load(path+'stopwords.npy')\n",
    "news_df = pd.read_pickle(path+'news_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMvEt5NzLmIJ"
   },
   "outputs": [],
   "source": [
    "freq_map={}\n",
    "ps=PorterStemmer()\n",
    "for article in news_df['Article']:\n",
    "    word_list=word_tokenize(article)\n",
    "    article_map={}\n",
    "    for word in word_list:\n",
    "        word=word.replace('\\n','').replace('-',' ')\n",
    "        if len(word)>2:\n",
    "            if word.isalpha():\n",
    "                if word not in stopwords:\n",
    "                    word_s=ps.stem(word)\n",
    "                    if word_s not in stopwords:\n",
    "                      try :\n",
    "                        float(word_s.replace(',',''))\n",
    "                        continue\n",
    "                      except :  \n",
    "                        if word_s not in article_map:\n",
    "                            if word_s in freq_map:\n",
    "                                freq_map[word_s]+=1\n",
    "                            else:\n",
    "                                freq_map[word_s]=1\n",
    "                            article_map[word_s]=1    \n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-htw45wL4KC"
   },
   "outputs": [],
   "source": [
    "number_of_articles=len(news_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjuXFmihL80n"
   },
   "outputs": [],
   "source": [
    "word_to_index={}\n",
    "index_to_word={}\n",
    "index=0\n",
    "for key in freq_map:\n",
    "  word_to_index[key]=index\n",
    "  index_to_word[index]=key\n",
    "  index+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpg5LOYEHdUI"
   },
   "outputs": [],
   "source": [
    "#del vector_space_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LivL1382MCLl"
   },
   "outputs": [],
   "source": [
    "#del vector_space_table\n",
    "vector_space_table=np.load(path+'vector_space_table2.npy')\n",
    "#print(\"yes1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcUNL4x8MKRe"
   },
   "outputs": [],
   "source": [
    "number_of_terms=len(freq_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Emj5c-MwMx5q"
   },
   "outputs": [],
   "source": [
    "number_of_topics=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8SeFblNOI0e"
   },
   "outputs": [],
   "source": [
    "w_z=np.random.rand(number_of_topics,number_of_terms)\n",
    "z_d=np.random.rand(number_of_articles,number_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mAYVoiz4OKgW"
   },
   "outputs": [],
   "source": [
    "sum_w_z=sum(w_z)\n",
    "w_z/=sum_w_z\n",
    "sum_z_d=sum(z_d)\n",
    "z_d/=sum(z_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIIdAQ4Mhw9Y"
   },
   "outputs": [],
   "source": [
    "#del article_dict_list\n",
    "article_dict_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWS9Y2c8dfGS"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(number_of_articles):\n",
    "  doc_word_map={}\n",
    "  for j in range(number_of_terms):\n",
    "    if(vector_space_table[i][j]>0):\n",
    "      doc_word_map[j]=np.zeros(number_of_topics)\n",
    "  article_dict_list.append(doc_word_map)    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hQBWCtFw2gz"
   },
   "outputs": [],
   "source": [
    "word_doc_map={}\n",
    "for j in range(number_of_terms):\n",
    "  word_doc_map[j]=[]\n",
    "  for i in range(number_of_articles):\n",
    "    if(vector_space_table[i][j]>0):\n",
    "      word_doc_map[j].append(i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HIOEQN3UHci"
   },
   "outputs": [],
   "source": [
    "# p=np.zeros(shape=(number_of_articles,number_of_terms,number_of_topics))\n",
    "# print(\"yes4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vxqLRgDUIOI"
   },
   "outputs": [],
   "source": [
    "def E_step():\n",
    "  for i in range(0,number_of_articles):\n",
    "    if(i%1000==0):\n",
    "      print(i)\n",
    "    #list_terms=[key for key in ]\n",
    "    for j in article_dict_list[i]:\n",
    "\n",
    "\n",
    "      denominator=0\n",
    "      for k in range(number_of_topics):\n",
    "        article_dict_list[i][j][k]=z_d[i][k]*w_z[k][j]\n",
    "\n",
    "        denominator+=article_dict_list[i][j][k]\n",
    "      if (denominator !=0):\n",
    "        for k in range(number_of_topics):\n",
    "          article_dict_list[i][j][k]=article_dict_list[i][j][k]/denominator\n",
    "      else:\n",
    "        for k in range(number_of_topics):\n",
    "          article_dict_list[i][j][k]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bolmvr9hc5Ns"
   },
   "outputs": [],
   "source": [
    "def M_step():\n",
    "  #update w_z\n",
    "  for k in range(number_of_topics):\n",
    "    if(k%20==0):\n",
    "      print(k)\n",
    "\n",
    "    denominator=0\n",
    "    for j in range(number_of_terms):\n",
    "      w_z[k][j]=0\n",
    "      for i in word_doc_map[j]:\n",
    "        if vector_space_table[i][j]!=0:\n",
    "          w_z[k][j]+=vector_space_table[i][j]*article_dict_list[i][j][k]\n",
    "        denominator+=w_z[k][j]\n",
    "    if(denominator!=0):\n",
    "      for j in range(number_of_terms):\n",
    "        w_z[k][j]/=denominator\n",
    "    else:\n",
    "      for j in range(number_of_terms):\n",
    "        w_z[k][j]=1.0/number_of_terms\n",
    "#   den_mat=np.zeros(number_of_topics)\n",
    "#   #  del w_z\n",
    "#   w_z=np.zeros(shape=(number_of_topics,number_of_terms))\n",
    "#   for i in range(number_of_articles):\n",
    "#   #     if(i%1000==0):\n",
    "#   #       print(i)\n",
    "#     for k in range (number_of_topics):\n",
    "#       for j in article_dict_list[i]:\n",
    "#           w_z[k][j]+=vector_space_table[i][j]*article_dict_list[i][j][k]\n",
    "#           den_mat[k]+=w_z[k][j]\n",
    "#   for k in range(number_of_topics):\n",
    "#     if den_mat[k]!=0:\n",
    "#       for j in range(number_of_terms):\n",
    "#         w_z[k][j]/=den_mat[k]\n",
    "#     else:\n",
    "#       for j in range(number_of_terms):\n",
    "#         w_z[k][j]=1.0/number_of_terms\n",
    "#   del den_mat      \n",
    " #update z_d\n",
    "\n",
    "  for i in range(number_of_articles):\n",
    "    if(i%2000==0):\n",
    "      print(i)\n",
    "    for k in range(number_of_topics):\n",
    "      #print('\\n')\n",
    "      z_d[i][k]=0\n",
    "      denominator=0\n",
    "      for j in article_dict_list[i]:\n",
    "        #if(vector_space_table[i][j]==0):\n",
    "         # print(\"dafuq\")\n",
    "        z_d[i][k]+=vector_space_table[i][j]*article_dict_list[i][j][k]\n",
    "        denominator+=vector_space_table[i][j]\n",
    "#       if(i%10==0 and k%10==0):\n",
    "#         print(denominator)\n",
    "      if (denominator!=0):\n",
    "        z_d[i][k]/=denominator\n",
    "#         if(i%10==0):\n",
    "          \n",
    "#           print(z_d[i][k])\n",
    "      else:\n",
    "        #print(\"hello\")\n",
    "        z_d[i][k]=1.0/number_of_topics\n",
    "  return w_z     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTjA51BGuyhB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTJ3N_NSvZxB"
   },
   "outputs": [],
   "source": [
    "num_iters=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nMJihiB8KMN"
   },
   "outputs": [],
   "source": [
    "w_z=np.load(path+'w_z.npy')\n",
    "z_d=np.load(path+'z_d.npy')\n",
    "article_dict_list=np.load(path+'article_dict_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zym3W9Jbszu0"
   },
   "outputs": [],
   "source": [
    "for i in range(num_iters):\n",
    "    print(\"Iter: \"+str(i))\n",
    "    E_step()\n",
    "    M_step()\n",
    "    if(i%5==0):\n",
    "      if(i==5):\n",
    "        print(z_d[0])\n",
    "        print(z_d[1])\n",
    "      np.save(path+'w_z',w_z)\n",
    "      np.save(path+'z_d',z_d)\n",
    "      np.save(path+'article_dict_list',article_dict_list)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zkMHzL5w8LJ4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RClGLRL6vt9l",
    "outputId": "b4c34466-9e31-4119-87ce-3edbb098fde7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: 1\n",
      "china, chines, compani, said, hong, govern, beij, kong, trade, year, \n",
      "Topic: 2\n",
      "sander, voter, clinton, poll, vote, state, democrat, primari, percent, win, \n",
      "Topic: 3\n",
      "said, hospit, fire, bodi, report, die, peopl, death, one, day, \n",
      "Topic: 4\n",
      "countri, said, govern, refuge, european, nation, europ, franc, year, intern, \n",
      "Topic: 5\n",
      "said, bank, israel, compani, isra, palestinian, custom, use, secur, offer, \n",
      "Topic: 6\n",
      "friend, want, just, didn, know, day, time, get, ask, never, \n",
      "Topic: 7\n",
      "said, match, open, play, tenni, djokov, player, french, tournament, year, \n",
      "Topic: 8\n",
      "said, attack, islam, state, kill, group, govern, forc, militari, war, \n",
      "Topic: 9\n",
      "appl, app, can, use, servic, like, compani, will, phone, new, \n",
      "Topic: 10\n",
      "britain, european, union, british, vote, leav, london, referendum, said, europ, \n",
      "Topic: 11\n",
      "dog, like, one, peopl, can, even, cloud, world, make, way, \n",
      "Topic: 12\n",
      "film, show, movi, like, said, one, charact, star, watch, seri, \n",
      "Topic: 13\n",
      "hit, run, game, yanke, said, inning, pitch, first, season, two, \n",
      "Topic: 14\n",
      "book, girl, read, write, said, like, novel, stori, school, one, \n",
      "Topic: 15\n",
      "game, goal, first, said, play, score, second, two, team, seri, \n",
      "Topic: 16\n",
      "women, ali, said, sexual, sex, men, woman, peopl, femal, rape, \n",
      "Topic: 17\n",
      "test, said, health, zika, women, viru, state, abort, infect, case, \n",
      "Topic: 18\n",
      "music, song, like, one, said, album, princ, new, play, perform, \n",
      "Topic: 19\n",
      "state, said, investig, citi, new, mayor, york, blasio, governor, cuomo, \n",
      "Topic: 20\n",
      "club, spain, leagu, team, player, year, madrid, champion, one, win, \n",
      "Topic: 21\n",
      "parti, said, polit, presid, ryan, senat, brazil, leader, hous, former, \n",
      "Topic: 22\n",
      "gay, orlando, said, peopl, transgend, mateen, bathroom, shoot, nightclub, lesbian, \n",
      "Topic: 23\n",
      "financi, bank, money, compani, fund, invest, billion, investor, firm, loan, \n",
      "Topic: 24\n",
      "car, said, vehicl, recal, safeti, compani, model, drive, driver, takata, \n",
      "Topic: 25\n",
      "room, hous, home, said, hotel, one, live, two, park, open, \n",
      "Topic: 26\n",
      "art, work, artist, museum, said, exhibit, new, one, year, will, \n",
      "Topic: 27\n",
      "north, said, south, korea, volkswagen, unit, state, fire, korean, kim, \n",
      "Topic: 28\n",
      "research, studi, scientist, can, cancer, one, said, like, human, peopl, \n",
      "Topic: 29\n",
      "presid, obama, democrat, elect, hous, polit, vote, will, leader, senat, \n",
      "Topic: 30\n",
      "think, peopl, thing, don, know, can, get, want, like, work, \n",
      "Topic: 31\n",
      "law, court, rule, state, said, justic, right, feder, case, legal, \n",
      "Topic: 32\n",
      "school, student, educ, colleg, univers, said, class, year, teacher, graduat, \n",
      "Topic: 33\n",
      "show, broadway, said, play, music, hamilton, theater, will, toni, year, \n",
      "Topic: 34\n",
      "compani, energi, said, deal, billion, year, will, climat, industri, percent, \n",
      "Topic: 35\n",
      "said, water, citi, peopl, island, year, one, can, day, local, \n",
      "Topic: 36\n",
      "said, one, kenya, just, year, day, kenyatta, can, call, like, \n",
      "Topic: 37\n",
      "time, articl, new, report, news, publish, york, editor, public, newspap, \n",
      "Topic: 38\n",
      "trump, republican, campaign, said, candid, senat, parti, donald, support, democrat, \n",
      "Topic: 39\n",
      "drug, said, health, patient, care, medic, doctor, hospit, can, use, \n",
      "Topic: 40\n",
      "state, unit, said, american, militari, offici, nation, iran, saudi, presid, \n",
      "Topic: 41\n",
      "said, say, one, like, just, year, get, luke, shoe, want, \n",
      "Topic: 42\n",
      "food, restaur, cook, like, can, make, said, recip, one, eat, \n",
      "Topic: 43\n",
      "said, danc, ballet, wed, dancer, revolut, work, allen, one, cultur, \n",
      "Topic: 44\n",
      "percent, rate, year, economi, market, econom, increas, said, job, growth, \n",
      "Topic: 45\n",
      "polic, said, offic, gun, shoot, kill, arrest, shot, man, video, \n",
      "Topic: 46\n",
      "clinton, said, campaign, presid, hillari, speech, use, polit, attack, say, \n",
      "Topic: 47\n",
      "father, new, mother, son, univers, york, famili, graduat, work, daughter, \n",
      "Topic: 48\n",
      "board, redston, said, compani, viacom, director, execut, trust, control, lawyer, \n",
      "Topic: 49\n",
      "said, design, store, card, like, custom, new, can, use, shop, \n",
      "Topic: 50\n",
      "case, said, court, judg, lawyer, charg, investig, offic, prosecutor, prison, \n",
      "Topic: 51\n",
      "met, said, collin, wright, syndergaard, walker, matz, back, season, will, \n",
      "Topic: 52\n",
      "season, driver, uber, year, race, first, last, time, quarter, seri, \n",
      "Topic: 53\n",
      "team, island, cup, world, game, said, unit, argentina, state, copa, \n",
      "Topic: 54\n",
      "said, turkey, erdogan, turkish, one, name, marathon, can, run, like, \n",
      "Topic: 55\n",
      "citi, build, new, said, street, york, brooklyn, park, apart, neighborhood, \n",
      "Topic: 56\n",
      "million, price, market, insur, cost, ticket, percent, bond, new, year, \n",
      "Topic: 57\n",
      "facebook, twitter, media, post, social, peopl, news, said, europ, european, \n",
      "Topic: 58\n",
      "said, travel, flight, airport, plane, secur, airlin, sea, passeng, island, \n",
      "Topic: 59\n",
      "art, million, said, auction, museum, sale, work, new, year, will, \n",
      "Topic: 60\n",
      "like, can, wine, one, bottl, use, look, make, get, say, \n",
      "Topic: 61\n",
      "fan, team, game, soccer, franc, stadium, will, match, england, championship, \n",
      "Topic: 62\n",
      "said, compani, new, tax, busi, execut, program, million, plan, advertis, \n",
      "Topic: 63\n",
      "game, point, said, warrior, curri, jame, team, play, final, first, \n",
      "Topic: 64\n",
      "fashion, design, said, show, wear, will, dress, new, year, like, \n",
      "Topic: 65\n",
      "olymp, athlet, russian, said, russia, sport, dope, rio, puerto, game, \n",
      "Topic: 66\n",
      "compani, sale, said, year, busi, percent, new, execut, chief, retail, \n",
      "Topic: 67\n",
      "race, hors, said, one, derbi, like, track, time, year, last, \n",
      "Topic: 68\n",
      "black, said, church, white, state, children, peopl, counti, racial, mani, \n",
      "Topic: 69\n",
      "googl, said, golf, cuban, day, hole, round, cuba, one, johnson, \n",
      "Topic: 70\n",
      "player, team, said, coach, leagu, year, play, sport, draft, season, "
     ]
    }
   ],
   "source": [
    "\n",
    "for k in range(number_of_topics):\n",
    "  print('\\n'+\"Topic: \"+str(k+1))\n",
    "  words_in_this_topic=[]\n",
    "  word_indices=w_z[k,:].argsort()\n",
    "  for i in range(1,11):\n",
    "    print(index_to_word[word_indices[-i]]+\", \",end='')\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6ICXxyJ3VuS"
   },
   "outputs": [],
   "source": [
    "num_iters=50\n",
    "for i in range(0, num_iters):\n",
    "    print(\"Iter: \"+str(i))\n",
    "    E_step()\n",
    "    w_z,z_d=M_step(w_z,z_d)\n",
    "    if(i%5==0):\n",
    "      np.save(path+'w_z',w_z)\n",
    "      np.save(path+'z_d',z_d)\n",
    "      np.save(path+'article_dict_list',article_dict_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pclg9kIm8aTk"
   },
   "outputs": [],
   "source": [
    "w_z=np.load(path+'w_z.npy')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "plsi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

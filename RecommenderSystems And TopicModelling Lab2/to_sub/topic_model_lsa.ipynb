{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"data/\"\n",
    "news_path=path+\"nytimes_news_articles.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(url):\n",
    "    date=url[28:38]\n",
    "    rest_of_url=url[39:]\n",
    "    category_slash=rest_of_url.find('/')\n",
    "    category=rest_of_url[:category_slash]\n",
    "    rest_of_url=rest_of_url[category_slash+1:]\n",
    "    subcategory=\"NIL\"\n",
    "    if(rest_of_url.find('/')!=-1):\n",
    "        subcategory_slash=rest_of_url.find('/')\n",
    "        subcategory=rest_of_url[:subcategory_slash]    \n",
    "        rest_of_url=rest_of_url[subcategory_slash+1:]    \n",
    "    title=rest_of_url[:-5]\n",
    "    title=title.replace('-',' ')\n",
    "    return date,category,subcategory,title\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=[]\n",
    "Date=[]\n",
    "Article=[]\n",
    "Category=[]\n",
    "Subcategory=[]\n",
    "Title=[]\n",
    "with open(news_path) as news_file:\n",
    "    line=news_file.readline()\n",
    "    while line:\n",
    "        URL.append(line[5:])\n",
    "        date_,category_,subcategory_,title_=parse_url(line)\n",
    "        Date.append(date_)\n",
    "        Category.append(category_)\n",
    "        Subcategory.append(subcategory_)\n",
    "        Title.append(title_)\n",
    "        #print(title_)\n",
    "        article_=\"\"\n",
    "        line=news_file.readline()\n",
    "        while line and line[:4]!=\"URL:\":\n",
    "            article_+=line+\" \"\n",
    "            line=news_file.readline()\n",
    "        Article.append(article_[2:].replace('\\n',''))    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df=pd.DataFrame()\n",
    "news_df['URL']=URL\n",
    "news_df['Date']=Date\n",
    "news_df['Category']=Category\n",
    "news_df['Subcategory']=Subcategory\n",
    "news_df['Article']=Article\n",
    "news_df['Title']=Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Article</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.nytimes.com/2016/06/30/sports/baseb...</td>\n",
       "      <td>2016/06/30</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball</td>\n",
       "      <td>WASHINGTON — Stellar pitching kept the Mets af...</td>\n",
       "      <td>washington nationals max scherzer baffles mets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.nytimes.com/2016/06/30/nyregion/may...</td>\n",
       "      <td>2016/06/30</td>\n",
       "      <td>nyregion</td>\n",
       "      <td>NIL</td>\n",
       "      <td>Mayor Bill de Blasio’s counsel and chief legal...</td>\n",
       "      <td>mayor de blasios counsel to leave next month t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.nytimes.com/2016/06/30/nyregion/thr...</td>\n",
       "      <td>2016/06/30</td>\n",
       "      <td>nyregion</td>\n",
       "      <td>NIL</td>\n",
       "      <td>In the early morning hours of Labor Day last y...</td>\n",
       "      <td>three men charged in killing of cuomo administ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.nytimes.com/2016/06/30/nyregion/tek...</td>\n",
       "      <td>2016/06/30</td>\n",
       "      <td>nyregion</td>\n",
       "      <td>NIL</td>\n",
       "      <td>It was the Apple Store in New York City before...</td>\n",
       "      <td>tekserve precursor to the apple store to close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.nytimes.com/2016/06/30/sports/olymp...</td>\n",
       "      <td>2016/06/30</td>\n",
       "      <td>sports</td>\n",
       "      <td>olympics</td>\n",
       "      <td>OMAHA — The United States Olympic swimming tri...</td>\n",
       "      <td>once at michael phelpss feet and still chasing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL        Date  Category  \\\n",
       "0  http://www.nytimes.com/2016/06/30/sports/baseb...  2016/06/30    sports   \n",
       "1  http://www.nytimes.com/2016/06/30/nyregion/may...  2016/06/30  nyregion   \n",
       "2  http://www.nytimes.com/2016/06/30/nyregion/thr...  2016/06/30  nyregion   \n",
       "3  http://www.nytimes.com/2016/06/30/nyregion/tek...  2016/06/30  nyregion   \n",
       "4  http://www.nytimes.com/2016/06/30/sports/olymp...  2016/06/30    sports   \n",
       "\n",
       "  Subcategory                                            Article  \\\n",
       "0    baseball  WASHINGTON — Stellar pitching kept the Mets af...   \n",
       "1         NIL  Mayor Bill de Blasio’s counsel and chief legal...   \n",
       "2         NIL  In the early morning hours of Labor Day last y...   \n",
       "3         NIL  It was the Apple Store in New York City before...   \n",
       "4    olympics  OMAHA — The United States Olympic swimming tri...   \n",
       "\n",
       "                                               Title  \n",
       "0  washington nationals max scherzer baffles mets...  \n",
       "1  mayor de blasios counsel to leave next month t...  \n",
       "2  three men charged in killing of cuomo administ...  \n",
       "3  tekserve precursor to the apple store to close...  \n",
       "4  once at michael phelpss feet and still chasing...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "arts\n",
      "science\n",
      "travel\n",
      "magazine\n",
      "world\n",
      "technology\n",
      "t-magazine\n",
      "fashion\n",
      "nyregion\n",
      "jobs\n",
      "upshot\n",
      "education\n",
      "universal\n",
      "theater\n",
      "nytnow\n",
      "sports\n",
      "us\n",
      "books\n",
      "style\n",
      "dining\n",
      "automobiles\n",
      "insider\n",
      "pageoneplus\n",
      "health\n",
      "realestate\n",
      "movies\n",
      "business\n",
      "your-money\n"
     ]
    }
   ],
   "source": [
    "category_set=set(Category)\n",
    "print(len(category_set))\n",
    "for category in category_set:\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "weddings\n",
      "food\n",
      "tennis\n",
      "smallbusiness\n",
      "travel\n",
      "americas\n",
      "europe\n",
      "what-in-the-world\n",
      "soccer\n",
      "design\n",
      "cycling\n",
      "energy-environment\n",
      "australia\n",
      "ncaafootball\n",
      "events\n",
      "elections\n",
      "mens-style\n",
      "commercial\n",
      "fashion\n",
      "review\n",
      "middleeast\n",
      "international\n",
      "africa\n",
      "football\n",
      "asia\n",
      "baseball\n",
      "art\n",
      "student-loans\n",
      "auto-insurance\n",
      "golf\n",
      "sailing\n",
      "artsspecial\n",
      "NIL\n",
      "music\n",
      "television\n",
      "horse-racing\n",
      "economy\n",
      "ncaabasketball\n",
      "politics\n",
      "personaltech\n",
      "wheels\n",
      "autoracing\n",
      "cricket\n",
      "dealbook\n",
      "olympics\n",
      "autoreviews\n",
      "media\n",
      "rugby\n",
      "basketball\n",
      "entertainment\n",
      "ko\n",
      "hockey\n",
      "dance\n"
     ]
    }
   ],
   "source": [
    "subcategory_set=set(Subcategory)\n",
    "print(len(subcategory_set))\n",
    "for category in subcategory_set:\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path=path+\"stopwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=[]\n",
    "with open(stopwords_path) as stopwords_file:\n",
    "    line=stopwords_file.readline().replace('\\n','').replace('-',' ')\n",
    "    while line:\n",
    "        stopwords.append(line)\n",
    "        line=stopwords_file.readline()[:-1].replace('\\n','').replace('-',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-44210f469e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "np.save(path+'stopwords',stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=np.load(path+'stopwords.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_map={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "for article in news_df['Article']:\n",
    "    word_list=word_tokenize(article)\n",
    "\n",
    "    for word in word_list:\n",
    "        if word not in stopwords:\n",
    "            word_s=ps.stem(word)\n",
    "            if word_s in freq_map:\n",
    "                freq_map[word_s]+=1\n",
    "            else:\n",
    "                freq_map[word_s]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_map=np.load(path+'freq_map.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111576"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles=len(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_space_table=np.zeros(shape=(number_of_articles,len(freq_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index={}\n",
    "index_to_word={}\n",
    "index=0\n",
    "for key in freq_map:\n",
    "    word_to_index[key]=index\n",
    "    index_to_word[index]=key\n",
    "    index+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(number_of_articles):\n",
    "  article=news_df['Article'][i]\n",
    "  word_list=word_tokenize(article)\n",
    "  article_map={}\n",
    "  for word in word_list:\n",
    "    word=word.replace('\\n','').replace('-',' ')\n",
    "    if len(word)>2:\n",
    "      if word.isalpha():\n",
    "        if word not in stopwords:\n",
    "          word_s=ps.stem(word)\n",
    "          if word_s not in stopwords:\n",
    "            try :\n",
    "              float(word_s.replace(',',''))\n",
    "              continue\n",
    "            except :  \n",
    "              if word_s in article_map:\n",
    "                article_map[word_s]+=1\n",
    "              else:\n",
    "                article_map[word_s]=1\n",
    "  for word in article_map:\n",
    "    map_index=word_to_index[word]\n",
    "    freq_art=article_map[word]\n",
    "    freq_total=freq_map[word]\n",
    "    vector_space_table[i][map_index]=freq_art*np.log(number_of_articles/number_of_occ[map_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_rank_k(mat,num):\n",
    "    u,s,vh=np.linalg.svd(mat, full_matrices= False)\n",
    "    u = u[:,:num]\n",
    "    vh = vh[:num,:]\n",
    "    s = s[:num]\n",
    "    s = np.diag(s)\n",
    "    #my_low_rank = np.dot(np.dot(u,s),vh)\n",
    "    return u,s,vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+'u',u)\n",
    "np.save(path+'s',s)\n",
    "np.save(path+'vh',vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(70):\n",
    "  topic_vector=u[:,i]\n",
    "  word_list=[]\n",
    "  for j in range(len(freq_map)):\n",
    "    current_vector=vector_space_table[:,j]\n",
    "    val=np.dot(vector_space_table[:,j],u[:,i])\n",
    "    word_list.append((val,j))\n",
    "  print(\"Topic \"+str(i+1)+\" : \")\n",
    "  word_list.sort(key=lambda x: x[0],reverse=True)\n",
    "  for i in range(10):\n",
    "    print(index_to_word[word_list[i][1]]+\",\",end='')\n",
    "  print('\\n')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
